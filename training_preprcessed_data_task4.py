# -*- coding: utf-8 -*-
"""training_preprcessed_data_task4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hxapxQvSFK1cDxIryLQUoCjhjXqyZGHi
"""

import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler

K=10
split=0.75

"""Function to load the data"""

def load_data (path: str="/path/to/csv"):
  df = pd.read_csv(F"{path}")
  df.drop(columns=["Unnamed:0"], inplace=True, errors = 'ignore')
  return df

"""Function to create target and predictor variables"""

def target_predictors( data: pd.DataFrame = None) :
    X = data.drop(columns=["estimated_stock_pct"])
    y=data["estimated_stock_pct"]
    return X, y

"""function to train the algorithm"""

def train_cross_validation (X: pd.DataFrame =None,
                            y: pd.Series = None) :
  accuracy = []
  for fold in range(0,K) :
    model = RandomForestRegressor()
    scaler = StandardScaler()

    X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = split, random_state=42)

    scaler.fit(X_train)
    X_train= scaler.transform(X_train)
    X_test= scaler.transform(X_test)

    trained_model = model.fit(X_train, y_train)

    y_pred = trained_model.predict(X_test)

    mae = mean_absolute_error(y_true=y_test, y_pred=y_pred)
    accuracy.append(mae)
    print(f"fold{fold+1}:: MAE = {mae:.3f}")

  print(f"Average MAE: {(sum(accuracy)/ len(accuracy)):.2f}")

"""Assuming that the data is already cleaned and processed, we will do the prective modelling"""

from google.colab import drive
drive.mount('/content/drive')

df = load_data("/content/drive/MyDrive/AI_Virtual_Internship_Cognizant/Processed Data.csv")
df.head()

# Now split the data into predictors and target variables
X, y = target_predictors(data=df)

# Finally, train the machine learning model
train_cross_validation(X=X, y=y)

